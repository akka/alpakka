# AWS S3

The AWS S3 connector provides Akka Stream sources and sinks to connect to [Amazon S3](https://aws.amazon.com/s3/).
S3 stands for Simple Storage Service and is an object storage service with a web service interface.

### Reported issues

[Tagged issues at Github](https://github.com/akka/alpakka/labels/p%3Aaws-s3)

## Artifacts

@@dependency [sbt,Maven,Gradle] {
  group=com.lightbend.akka
  artifact=akka-stream-alpakka-s3_$scalaBinaryVersion$
  version=$version$
}

## Usage

### Set up your S3 clients

The S3 connector can be configured within your `application.conf` file.

Configuration
: @@snip [snip](/s3/src/main/resources/reference.conf)

### Create an S3 client

Scala
: @@snip [snip](/s3/src/test/scala/akka/stream/alpakka/s3/scaladsl/S3SourceSpec.scala) { #client }

Java
: @@snip [snip](/s3/src/test/java/akka/stream/alpakka/s3/javadsl/S3ClientTest.java) { #client }

### Storing a file in S3

Scala
: @@snip [snip](/s3/src/test/scala/akka/stream/alpakka/s3/scaladsl/S3SinkSpec.scala) { #upload }

Java
: @@snip [snip](/s3/src/test/java/akka/stream/alpakka/s3/javadsl/S3ClientTest.java) { #upload }

### Downloading a file from S3

Scala
: @@snip [snip](/s3/src/test/scala/akka/stream/alpakka/s3/scaladsl/S3SourceSpec.scala) { #download }

Java
: @@snip [snip](/s3/src/test/java/akka/stream/alpakka/s3/javadsl/S3ClientTest.java) { #download }

In order to download a range of a file's data you can use overloaded method which
additionally takes `ByteRange` as argument.

Scala
: @@snip [snip](/s3/src/test/scala/akka/stream/alpakka/s3/scaladsl/S3SourceSpec.scala) { #rangedDownload }

Java
: @@snip [snip](/s3/src/test/java/akka/stream/alpakka/s3/javadsl/S3ClientTest.java) { #rangedDownload }

#### Accessing object metadata

When downloading an object you also get the object's metadata with it. 
Here's an example of using this metadata to stream an object back to a client in akka http

```scala
val (data, eventualMeta) = s3Client.download(bucket, objectKey)
complete( eventualMeta.map ( meta â‡’
  HttpResponse(
    entity = HttpEntity(
      meta.contentType.flatMap(ContentType.parse(_).toOption).getOrElse(`application/octet-stream`),
      meta.contentLength,
      data
    )
  )
))
```

### Accessing object metadata without downloading object from S3

Scala
: @@snip [snip](/s3/src/test/scala/akka/stream/alpakka/s3/scaladsl/S3SourceSpec.scala) { #objectMetadata }

Java
: @@snip [snip](/s3/src/test/java/akka/stream/alpakka/s3/javadsl/S3ClientTest.java) { #objectMetadata }

### List bucket contents

Scala
: @@snip [snip](/s3/src/test/scala/akka/stream/alpakka/s3/scaladsl/S3SourceSpec.scala) { #list-bucket }

Java
: @@snip [snip](/s3/src/test/java/akka/stream/alpakka/s3/javadsl/S3ClientTest.java) { #list-bucket }

### Copy upload (multi part)

Copy an S3 object from source bucket to target bucket using multi part copy upload.

Scala
: @@snip [snip](/s3/src/test/scala/akka/stream/alpakka/s3/scaladsl/S3SinkSpec.scala) { #multipart-copy }

Java
: @@snip [snip](/s3/src/test/java/akka/stream/alpakka/s3/javadsl/S3ClientTest.java) { #multipart-copy }

### Copy upload (multi part) a specific version of source object

Copy an S3 object from source bucket to target bucket using multi part copy upload. If your bucket has versioning 
enabled, you could have multiple versions of the same object. By default AWS identifies the current version of the 
object to copy. You can optionally specify a specific version of the source object to copy by adding the 
`sourceVersionId` parameter.

Scala
: @@snip [snip](/s3/src/test/scala/akka/stream/alpakka/s3/scaladsl/S3SinkSpec.scala) { #multipart-copy-with-source-version }

Java
: @@snip [snip](/s3/src/test/java/akka/stream/alpakka/s3/javadsl/S3ClientTest.java) { #multipart-copy-with-source-version }

#### Java examples with custom headers

Java
: @@snip [snip](/s3/src/test/java/akka/stream/alpakka/s3/javadsl/JavaExamplesSnippets.java) { #java-example }

### Running the example code

The code in this guide is part of runnable tests of this project. You are welcome to edit the code and run it in sbt.

Scala
:   ```
    sbt
    > s3/test
    ```

Java
:   ```
    sbt
    > s3/test
    ```

# Bluemix Cloud Object Storage with S3 API

The Alpakka S3 connector can connect to a range of S3 compatible services. One of them is IBM Bluemix Cloud Object Storage, which supports a dialect of the AWS S3 API.
Most functionality provided by the Alpakka S3 connector is compatible with Cloud Object Store, but there are a few limitations, which are listed below.

## Connection limitations

- This S3 connector does not support domain-style access for Cloud Object Store, so only path-style access is supported.
- Regions in COS are always part of the host/endpoint, therefore leave the s3Region field in S3Settings empty
- The object proxy, containing host/endpoint, port and scheme, must always be specified.

## External references

[IBM Cloud Object Storage Documentation](https://ibm-public-cos.github.io/crs-docs/api-reference)

## Example

Scala
: @@snip [snip](/s3/src/test/scala/akka/stream/alpakka/s3/scaladsl/DocSnippets.scala) { #scala-bluemix-example }

Java
: @@snip [snip](/s3/src/test/java/akka/stream/alpakka/s3/javadsl/DocSnippets.java) { #java-bluemix-example }
