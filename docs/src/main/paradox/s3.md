# AWS S3 Connector

The AWS S3 connector provides Akka Stream sources and sinks to connect to [Amazon S3](https://aws.amazon.com/s3/).
S3 stands for Simple Storage Service and is an object storage service with a web service interface.


### Reported issues

[Tagged issues at Github](https://github.com/akka/alpakka/labels/p%3Aaws-s3)


## Artifacts

@@dependency [sbt,Maven,Gradle] {
  group=com.lightbend.akka
  artifact=akka-stream-alpakka-s3_$scalaBinaryVersion$
  version=$version$
}

## Usage

### Set up your S3 clients

The S3 connector can be configured within your `application.conf` file.

Configuration
: @@snip ($alpakka$/s3/src/main/resources/reference.conf)

### Create an S3 client

Scala
: @@snip ($alpakka$/s3/src/test/scala/akka/stream/alpakka/s3/scaladsl/S3SourceSpec.scala) { #client }

Java
: @@snip ($alpakka$/s3/src/test/java/akka/stream/alpakka/s3/javadsl/S3ClientTest.java) { #client }

### Storing a file in S3

Scala
: @@snip ($alpakka$/s3/src/test/scala/akka/stream/alpakka/s3/scaladsl/S3SinkSpec.scala) { #upload }

Java
: @@snip ($alpakka$/s3/src/test/java/akka/stream/alpakka/s3/javadsl/S3ClientTest.java) { #upload }

### Downloading a file from S3

Scala
: @@snip ($alpakka$/s3/src/test/scala/akka/stream/alpakka/s3/scaladsl/S3SourceSpec.scala) { #download }

Java
: @@snip ($alpakka$/s3/src/test/java/akka/stream/alpakka/s3/javadsl/S3ClientTest.java) { #download }

In order to download a range of a file's data you can use overloaded method which
additionally takes `ByteRange` as argument.

Scala
: @@snip ($alpakka$/s3/src/test/scala/akka/stream/alpakka/s3/scaladsl/S3SourceSpec.scala) { #rangedDownload }

Java
: @@snip ($alpakka$/s3/src/test/java/akka/stream/alpakka/s3/javadsl/S3ClientTest.java) { #rangedDownload }

#### Accessing object metadata

When downloading an object you also get the object's metadata with it. 
Here's an example of using this metadata to stream an object back to a client in akka http

```scala
val (data, eventualMeta) = s3Client.download(bucket, objectKey)
complete( eventualMeta.map ( meta â‡’
  HttpResponse(
    entity = HttpEntity(
      meta.contentType.flatMap(ContentType.parse(_).toOption).getOrElse(`application/octet-stream`),
      meta.contentLength,
      data
    )
  )
))
```

### List bucket contents

Scala
: @@snip ($alpakka$/s3/src/test/scala/akka/stream/alpakka/s3/scaladsl/S3SourceSpec.scala) { #list-bucket }

Java
: @@snip ($alpakka$/s3/src/test/java/akka/stream/alpakka/s3/javadsl/S3ClientTest.java) { #list-bucket }

### Running the example code

The code in this guide is part of runnable tests of this project. You are welcome to edit the code and run it in sbt.

Scala
:   ```
    sbt
    > s3/test
    ```

Java
:   ```
    sbt
    > s3/test
    ```

# Bluemix Cloud Object Storage with S3 API

The Alpakka S3 connector can connect to a range of S3 compatible services. One of them is IBM Bluemix Cloud Object Storage, which supports a dialect of the AWS S3 API.
Most functionality provided by the Alpakka S3 connector is compatible with Cloud Object Store, but there are a few limitations, which are listed below.

## Connection limitations

- This S3 connector does not support domain-style access for Cloud Object Store, so only path-style access is supported.
- Regions in COS are always part of the host/endpoint, therefore leave the s3Region field in S3Settings empty
- The object proxy, containing host/endpoint, port and scheme, must always be specified.

## External references

[IBM Cloud Object Storage Documentation](https://ibm-public-cos.github.io/crs-docs/api-reference)

## Example

Scala
: @@snip ($alpakka$/s3/src/test/scala/akka/stream/alpakka/s3/scaladsl/DocSnippets.scala) { #scala-bluemix-example }

Java
: @@snip ($alpakka$/s3/src/test/java/akka/stream/alpakka/s3/javadsl/DocSnippets.java) { #java-bluemix-example }
